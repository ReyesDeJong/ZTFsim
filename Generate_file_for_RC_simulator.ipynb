{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python 2 and 3 comptibility\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import json\n",
    "import io\n",
    "import gzip\n",
    "import base64\n",
    "from astropy.io import fits\n",
    "import matplotlib.pylab as plt\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import sys \n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "PATH_TO_PROJECT = os.path.abspath(\n",
    "    os.path.join(os.path.dirname('__file__'), ''))\n",
    "sys.path.append(PATH_TO_PROJECT)\n",
    "sys.path.append(os.path.join(PATH_TO_PROJECT,'..'))\n",
    "\n",
    "data_path = '../AlerceDHtest/datasets/ZTF'\n",
    "\n",
    "path = data_path+'/broker_reals.json'\n",
    "with open(path, \"r\") as f:\n",
    "        dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate camera_obs_cond[\"obs_conditions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCircularMask(h, w, center=None, radius=None):\n",
    "\n",
    "    if center is None: # use the middle of the image\n",
    "        center = [int(w/2), int(h/2)]\n",
    "    if radius is None: # use the smallest distance between the center and image walls\n",
    "        radius = min(center[0], center[1], w-center[0], h-center[1])\n",
    "\n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    dist_from_center = np.sqrt((X - center[0])**2 + (Y-center[1])**2)\n",
    "\n",
    "    mask = dist_from_center <= radius\n",
    "    return mask\n",
    "\n",
    "def makeGaussian(size, fwhm = 3, center=None):\n",
    "    \"\"\" Make a square gaussian kernel.\n",
    "\n",
    "    size is the length of a side of the square\n",
    "    fwhm is full-width-half-maximum, which\n",
    "    can be thought of as an effective radius.\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.arange(0, size, 1, float)\n",
    "    y = x[:,np.newaxis]\n",
    "\n",
    "    if center is None:\n",
    "        x0 = y0 = size // 2\n",
    "    else:\n",
    "        x0 = center[0]\n",
    "        y0 = center[1]\n",
    "\n",
    "    return np.exp(-4*np.log(2) * ((x-x0)**2 + (y-y0)**2) / fwhm**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero point as in ZTF zp'= zp +2.5*log10(Texp)\n",
    "# and clip between 23-28 as in ZTF paper https://arxiv.org/abs/1902.01872\n",
    "def get_zero_point(stamp, aperture_mag, exp_time=30.0):\n",
    "    stamp_shape = stamp.shape\n",
    "    mask = createCircularMask(stamp_shape[0], stamp_shape[1], center=np.array(stamp_shape)/2, radius=8)\n",
    "    extracted_mask = np.multiply(mask, stamp)\n",
    "    count_photometry = np.nansum(extracted_mask)\n",
    "    #beacuse it is diff image\n",
    "    #if count_photometry < 0:\n",
    "    #    return [], [], np.nan\n",
    "    residual_image = stamp - extracted_mask\n",
    "    zero_point = aperture_mag + 2.5*np.log10(np.clip(count_photometry, a_min=1e-4, a_max=None))#/exp_time)\n",
    "    zero_point = np.clip(zero_point, a_min=23, a_max=28)\n",
    "    return zero_point, residual_image, count_photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build dict by alert id\n",
    "alerts = {}\n",
    "passbands = [\"g\", \"r\", \"i\"]\n",
    "for alert in dataset[\"query_result\"]:\n",
    "    dict_in_stamp = {'science_stamp':None, 'filter': None, 'fwhm': None, 'mjd': None, 'field': None, 'object_id': None}\n",
    "    #get params to save in dict\n",
    "    dict_in_stamp['filter'] = passbands[alert[\"candidate\"][\"fid\"]-1]\n",
    "    dict_in_stamp['fwhm'] = alert[\"candidate\"][\"fwhm\"]\n",
    "    dict_in_stamp['mjd'] = alert[\"candidate\"][\"jd\"]\n",
    "    dict_in_stamp['object_id'] = alert['objectId']\n",
    "    dict_in_stamp['field'] = alert[\"candidate\"][\"field\"]\n",
    "    dict_in_stamp['_id'] = alert[\"_id\"]\n",
    "    #other observation conditions\n",
    "    dict_in_stamp['airmass'] = 1.2# arcsen of angle of sight with respect to cenit\n",
    "    dict_in_stamp['exp_time'] = 30#alert[\"candidate\"][\"exptime\"]\n",
    "    dict_in_stamp['limmag3'] = None\n",
    "    dict_in_stamp['limmag5'] = alert[\"candidate\"][\"diffmaglim\"]\n",
    "    dict_in_stamp['obs_day'] = alert[\"candidate\"][\"jd\"]\n",
    "    dict_in_stamp['seeing'] = alert[\"candidate\"][\"fwhm\"]\n",
    "    #seeings shoulb be higher thn 2.0(?)\n",
    "    if dict_in_stamp['seeing']<=0.5:\n",
    "        dict_in_stamp['seeing'] = 2.0\n",
    "    dict_in_stamp['sky_brightness'] = None #Needs to be calculated from science stamp\n",
    "    #dict_in_stamp['zero_point'] =  1.0 #We dont have it but a constant is enough\n",
    "    #stamps\n",
    "    stamp = alert['cutoutScience']['stampData']\n",
    "    stamp = base64.b64decode(stamp[\"$binary\"].encode())\n",
    "    with gzip.open(io.BytesIO(stamp), 'rb') as f:\n",
    "        with fits.open(io.BytesIO(f.read())) as hdul:\n",
    "            img = hdul[0].data\n",
    "    dict_in_stamp['science_stamp'] = img\n",
    "    \n",
    "    #zero point\n",
    "    aperture_mag = alert[\"candidate\"][\"magap\"]\n",
    "    dict_in_stamp[\"magap\"] = aperture_mag\n",
    "    zero_point, res, c = get_zero_point(img, aperture_mag)\n",
    "    dict_in_stamp['zero_point'] = zero_point#24.5\n",
    "    \n",
    "    stamp_id = alert[\"_id\"]\n",
    "    \n",
    "    if stamp_id in alerts.keys():\n",
    "        print(stamp_id)\n",
    "        continue\n",
    "    else:\n",
    "        alerts[stamp_id] = dict_in_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add masked sky and sky array to dicts\n",
    "n_sigmas = 4\n",
    "\n",
    "#check if values are already in dict, to avoid second innecesarry runs\n",
    "if 'masked_sky' not in alerts[list(alerts.keys())[0]].keys():\n",
    "    for alert_id in alerts:\n",
    "        alert = alerts[alert_id] \n",
    "        fw = alert['fwhm']\n",
    "        mask = ~createCircularMask(alert['science_stamp'].shape[0], alert['science_stamp'].shape[1], radius=n_sigmas*(fw/2.35482))\n",
    "        masked_sky = alert['science_stamp']*mask\n",
    "        alert['masked_sky'] = masked_sky\n",
    "\n",
    "        sky_pixels_cord = np.argwhere(mask==True)\n",
    "        sky_pixels = np.array([masked_sky[cord[0],cord[1]] for cord in list(sky_pixels_cord)])\n",
    "        alert['sky_pixel_values'] = sky_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class to filter sky without considering nans\n",
    "class Sky_filter:\n",
    "\n",
    "    def __init__(self, sky_pixels, n_sigma=2, filter_iterations=5):\n",
    "        \n",
    "        self.n = n_sigma\n",
    "        self.sigmas = np.empty((0))\n",
    "        self.n_sigmas = np.empty((0))\n",
    "        self.sky_pixels = sky_pixels[np.logical_not(np.isnan(sky_pixels))]      \n",
    "        \n",
    "    def get_n_sigma(self, sky_pixels):\n",
    "        sigma = np.std(sky_pixels)\n",
    "        #print(np.mean(sky_pixels))\n",
    "        #print(np.mean(sky_pixels)+sigma)\n",
    "        n_sigma = np.mean(sky_pixels)+self.n*sigma\n",
    "        self.sigmas = np.append(self.sigmas,np.mean(sky_pixels)+sigma)\n",
    "        self.n_sigmas = np.append(self.n_sigmas,n_sigma)\n",
    "        return n_sigma\n",
    "    \n",
    "    def filter_sky_once(self):\n",
    "        last_filtered_sky = self.filtered_sky['it%i'%(len(list(self.filtered_sky.keys()))-1)]\n",
    "        n_sigma = self.get_n_sigma(last_filtered_sky)\n",
    "        pixels_over_sigma = np.abs(last_filtered_sky)>n_sigma\n",
    "        pixels_over_std_cord = np.argwhere(pixels_over_sigma==True)\n",
    "        #print(pixels_over_std_cord)\n",
    "        new_filtered_sky = np.delete(last_filtered_sky, pixels_over_std_cord)\n",
    "        self.filtered_sky['it%i'%len(list(self.filtered_sky.keys()))] = new_filtered_sky\n",
    "        \n",
    "    def iterative_filtering(self, iterations):\n",
    "        #print(self.sky_pixels.shape)\n",
    "        if np.isnan(self.sky_pixels).any():\n",
    "            return None\n",
    "            \n",
    "        self.sigmas = np.empty((0))\n",
    "        self.n_sigmas = np.empty((0))\n",
    "        self.filtered_sky = {'it0':self.sky_pixels}\n",
    "        for i in range(iterations):\n",
    "            self.filter_sky_once()\n",
    "        return self.filtered_sky\n",
    "\n",
    "    def check_availability(self, array, idx):\n",
    "        array = np.array(array)\n",
    "        if array.shape[0]-1<idx:\n",
    "            check_nans = self.iterative_filtering(idx+1)\n",
    "        if check_nans is None:\n",
    "            raise ValueError('nans in sky pixels')\n",
    "            \n",
    "    def plot_array(self, array):\n",
    "        array = np.array(array)\n",
    "        x = np.arange(0, array.shape[0])\n",
    "        plt.plot(x,array)\n",
    "            \n",
    "    def plot_filtered_sky_sigmas(self, idx=0, x_pos=32, y_pos=32):\n",
    "        self.check_availability(self.n_sigmas, idx)\n",
    "        \n",
    "        #plt.figure(figsize=(12,12))\n",
    "        line = np.arange(0,self.sky_pixels.shape[0])\n",
    "        n_sigma_line = np.full(self.sky_pixels.shape[0], self.n_sigmas[idx])\n",
    "        mean = np.full(self.sky_pixels.shape[0], np.mean(self.sky_pixels))\n",
    "        plt.scatter(line, self.sky_pixels)\n",
    "        #plt.lim(np.min(self.sky_pixels),np.max(self.sky_pixels))\n",
    "        plt.plot(line, n_sigma_line, color='black', label='sigma')\n",
    "        plt.plot(line, mean, '--', color='black', label='mean')\n",
    "        #print(self.sky_pixels)\n",
    "        #print(self.sky_pixels.shape)\n",
    "        plt.title(r'non-filtered $\\sigma$[%f], max: %f'%(self.n_sigmas[idx].round(decimals=3), np.max(self.sky_pixels)))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        filtered_sky = self.filtered_sky['it%i'%idx]\n",
    "        line = np.arange(0,filtered_sky.shape[0])\n",
    "        n_sigma_line = np.full(filtered_sky.shape[0], self.n_sigmas[idx])\n",
    "        mean = np.full(filtered_sky.shape[0], np.mean(filtered_sky))\n",
    "        plt.scatter(line, filtered_sky)\n",
    "        plt.plot(line, n_sigma_line, color='black', label='sigma')\n",
    "        plt.plot(line, mean, '--', color='black', label='mean')\n",
    "        plt.title(r'filtered $\\sigma$['+str(idx)+r']: '+str(self.n_sigmas[idx].round(decimals=3)))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        self.plot_array(self.n_sigmas)\n",
    "        plt.title(r'$\\sigma$´s progretions')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add filtered sky (after filter_iterations iterations) to dict\n",
    "filter_iterations = 10\n",
    "\n",
    "#check if values are already in dict, to avoid second innecesarry runs\n",
    "if 'filtered_sky_pixel_values' not in alerts[list(alerts.keys())[0]].keys():\n",
    "    #i=0\n",
    "    for alert_id in alerts:\n",
    "        #print(i)\n",
    "        #i+=1\n",
    "        alert = alerts[alert_id] \n",
    "        sky_values = alert['sky_pixel_values']\n",
    "        sky_filter = Sky_filter(sky_values)\n",
    "        filtered_sky = sky_filter.iterative_filtering(iterations=filter_iterations)\n",
    "        #get last iteration filtered sky\n",
    "        last_iteration_filtered_sky = filtered_sky[list(filtered_sky.keys())[-1]]\n",
    "        mean_sky_value = np.mean(last_iteration_filtered_sky)\n",
    "        #add data to dict\n",
    "        alert['filtered_sky_pixel_values'] = last_iteration_filtered_sky\n",
    "        alert['sky_value'] = mean_sky_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts[alert_id].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter alerts that have less than N_ALERTS_IN_OBJ_ID\n",
    "#all OBJ_ID\n",
    "all_obj_id = [alerts[alert_id]['object_id'] for alert_id in alerts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count mjds and generate dict mjd/count_mjd\n",
    "#TODO: add frequency to dict\n",
    "from collections import Counter\n",
    "object_id_group_dict = Counter(all_obj_id)\n",
    "#print(Counter(all_obj_id).keys()) # equals to list(set(words))\n",
    "#print(Counter(all_obj_id).values()) # counts the elements' frequency\n",
    "#plt.hist(Counter(all_obj_id).values(), bins=100)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter alerts that have less than N_ALERTS_IN_OBJ_ID freq\n",
    "N_ALERTS_IN_OBJ_ID = 20\n",
    "filtered_alerts = {}\n",
    "\n",
    "for alert_id in alerts:\n",
    "    alert_obj_id = alerts[alert_id]['object_id']\n",
    "    if object_id_group_dict[alert_obj_id]>=N_ALERTS_IN_OBJ_ID:\n",
    "        filtered_alerts[alert_id] = alerts[alert_id]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize channels\n",
    "#for alert in filtered_alerts:\n",
    "#    print(filtered_alerts[alert]['filter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Group alerts by field (every object is considered as a diferrent field)\n",
    "all_objectsId = [filtered_alerts[alert_id]['object_id'] for alert_id in filtered_alerts]\n",
    "objectId_uniques = np.unique(all_objectsId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_alerts[list(filtered_alerts.keys())[0]].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name field\n",
    "field_objectId_dict = {}\n",
    "for i, objectId in enumerate(objectId_uniques):\n",
    "    field_objectId_dict['Field%s' % str(i+1).zfill(2)] = objectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dict of fields as in https://github.com/rodrigcd/HiTS_simulations, but with the extra parameter calculed above\n",
    "camera_obs_cond_non_filtered = {}\n",
    "camera_obs_cond_non_filtered[\"obs_conditions\"] = {}\n",
    "for field in field_objectId_dict.keys():\n",
    "    camera_obs_cond_non_filtered[\"obs_conditions\"][field] = []\n",
    "    appended_alert_count = 0\n",
    "    for alert_id in filtered_alerts:\n",
    "        if filtered_alerts[alert_id]['object_id'] == field_objectId_dict[field]:\n",
    "            filtered_alerts[alert_id]['epoch'] = appended_alert_count+1\n",
    "            filtered_alerts[alert_id]['sky_brightness'] = filtered_alerts[alert_id]['sky_value']\n",
    "            camera_obs_cond_non_filtered[\"obs_conditions\"][field].append(filtered_alerts[alert_id])\n",
    "            appended_alert_count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove extra keys, and leave the ones for rodrigo\n",
    "camera_obs_cond = {}\n",
    "camera_obs_cond[\"obs_conditions\"] = {}\n",
    "\n",
    "for field in camera_obs_cond_non_filtered[\"obs_conditions\"].keys():\n",
    "    camera_obs_cond[\"obs_conditions\"][field] = []\n",
    "    for alert in camera_obs_cond_non_filtered[\"obs_conditions\"][field]:\n",
    "        aux_alert = {\n",
    "            'airmass': alert['airmass'],\n",
    "            'epoch': alert['epoch'],\n",
    "            'exp_time': alert['exp_time'],\n",
    "            'filter': alert['filter'],\n",
    "            'limmag3': alert['limmag3'],\n",
    "            'limmag5': alert['limmag5'],\n",
    "            'obs_day': alert['obs_day'], \n",
    "            'seeing': alert['seeing'],\n",
    "            'sky_brightness': alert['sky_brightness'],\n",
    "            'zero_point': alert['zero_point']\n",
    "        }\n",
    "        camera_obs_cond[\"obs_conditions\"][field].append(aux_alert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate camera_obs_cond['psf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_data_dict={\"g\":{}, \"r\":{}, \"i\":{}}\n",
    "for channel in psf_data_dict.keys():\n",
    "    psf_data_dict[channel]={\"n_alerts\":{}, \"stamp\":{}, \"jd\":{}, 'mean_stamps':{}, 'mean_stamp_masked':{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group alerts by channel and fwhm\n",
    "all_fwhm = []\n",
    "filters_ls = list(psf_data_dict.keys())\n",
    "for alert in dataset[\"query_result\"]:\n",
    "    fwhm = alert[\"candidate\"][\"fwhm\"]\n",
    "    jd = alert[\"candidate\"][\"jd\"]\n",
    "    fid = alert[\"candidate\"][\"fid\"]\n",
    "    all_fwhm.append(fwhm)\n",
    "    stamp = alert['cutoutDifference']['stampData']\n",
    "    stamp = base64.b64decode(stamp[\"$binary\"].encode())\n",
    "    with gzip.open(io.BytesIO(stamp), 'rb') as f:\n",
    "        with fits.open(io.BytesIO(f.read())) as hdul:\n",
    "            img = hdul[0].data\n",
    "\n",
    "    if fwhm in psf_data_dict[filters_ls[fid-1]]['n_alerts'].keys():\n",
    "        psf_data_dict[filters_ls[fid-1]]['n_alerts'][fwhm] += 1\n",
    "        psf_data_dict[filters_ls[fid-1]]['stamp'][fwhm].append(img)\n",
    "        psf_data_dict[filters_ls[fid-1]]['jd'][fwhm].append(jd)\n",
    "    else:\n",
    "        psf_data_dict[filters_ls[fid-1]]['n_alerts'][fwhm] = 1\n",
    "        psf_data_dict[filters_ls[fid-1]]['stamp'][fwhm] = [img,]\n",
    "        psf_data_dict[filters_ls[fid-1]]['jd'][fwhm] = [jd,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate mean stamp and masked mean\n",
    "n_sigmas = 3#4\n",
    "for channel in filters_ls:\n",
    "    n_alerts = psf_data_dict[channel]['n_alerts']\n",
    "    stamp_dict = psf_data_dict[channel]['stamp']\n",
    "    for j, fw in enumerate(n_alerts.keys()):\n",
    "        if fw>1 and fw<12 and n_alerts[fw] >= 10:\n",
    "            aux_stamp_dict = stamp_dict[fw][:]\n",
    "            for i, s in enumerate(aux_stamp_dict):\n",
    "                aux_stamp_dict[i] = np.nan_to_num(s)[21:42, 21:42]\n",
    "                aux_stamp_dict[i] = aux_stamp_dict[i]/np.sum(aux_stamp_dict[i])\n",
    "            aux_stamp_dict = np.stack(aux_stamp_dict)\n",
    "            #print(aux_stamp_dict.shape)\n",
    "            psf = np.mean(aux_stamp_dict, axis=0)\n",
    "            psf = psf/np.sum(psf)\n",
    "            \n",
    "            #mask\n",
    "            #mask = createCircularMask(21,21,radius=n_sigmas*(fw/2.35482))\n",
    "            mask = makeGaussian(21, fwhm = fw*n_sigmas, center=None)\n",
    "            masked_psf = mask*psf\n",
    "            masked_psf = masked_psf/np.sum(masked_psf)\n",
    "            \n",
    "            #append mean stamp\n",
    "            psf_data_dict[channel]['mean_stamps'][fw] = psf\n",
    "            psf_data_dict[channel]['mean_stamp_masked'][fw] = masked_psf\n",
    "            #if fw in psf_data_dict[channel]['mean_stamps'].keys():\n",
    "                #psf_data_dict[channel]['mean_stamps'][fw].append(psf)\n",
    "            #else:\n",
    "                #psf_data_dict[channel]['mean_stamps'][fw] = [psf,]\n",
    "\n",
    "            #append mask\n",
    "            #if fw in psf_data_dict[channel]['mean_stamp_masked'].keys():\n",
    "            #    psf_data_dict[channel]['mean_stamp_masked'][fw].append(masked_psf)\n",
    "            #else:\n",
    "                #psf_data_dict[channel]['mean_stamp_masked'][fw] = [masked_psf,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate psf's as in https://github.com/rodrigcd/HiTS_simulations\n",
    "print(psf_data_dict.keys())\n",
    "print(psf_data_dict[list(psf_data_dict.keys())[0]].keys())\n",
    "\n",
    "# mix psf's by channels\n",
    "PSFs_TO_CHOOSE_KEY = \"mean_stamp_masked\"\n",
    "#camera_obs_cond = {}\n",
    "camera_obs_cond[\"psf\"] = np.empty(list(psf_data_dict[list(psf_data_dict.keys())[0]][PSFs_TO_CHOOSE_KEY][list(psf_data_dict[list(psf_data_dict.keys())[0]][PSFs_TO_CHOOSE_KEY].keys())[0]].shape)+[0])\n",
    "\n",
    "for channel in psf_data_dict.keys():\n",
    "    for fwhm in psf_data_dict[channel][PSFs_TO_CHOOSE_KEY].keys():\n",
    "        camera_obs_cond[\"psf\"] = np.concatenate([camera_obs_cond[\"psf\"], psf_data_dict[channel][PSFs_TO_CHOOSE_KEY][fwhm][...,np.newaxis]], axis=-1)\n",
    "        \n",
    "camera_obs_cond[\"psf\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Manually filter outbad psfs\n",
    "psfs = camera_obs_cond[\"psf\"]\n",
    "#for i in range(psfs.shape[-1]):\n",
    "#    print(i)\n",
    "#    plt.imshow(psfs[...,i])\n",
    "#    plt.colorbar()\n",
    "#    plt.show()\n",
    "print(psfs.shape)\n",
    "print(np.mean(psfs>=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out psf with large negative values\n",
    "#and make negative pixels positive by NN mask\n",
    "psfs_filtered = []#np.empty(list(psf_data_dict[list(psf_data_dict.keys())[0]][PSFs_TO_CHOOSE_KEY][list(psf_data_dict[list(psf_data_dict.keys())[0]][PSFs_TO_CHOOSE_KEY].keys())[0]].shape)+[0])\n",
    "print(psfs.shape)\n",
    "print(np.mean(psfs>=0))\n",
    "for i in range(psfs.shape[-1]):\n",
    "    #print(np.amin(psfs[...,i]))\n",
    "    if np.amin(psfs[...,i])<=-0.0099:#i #in #filter_out:\n",
    "        continue\n",
    "    psfs_filtered.append(psfs[...,i])\n",
    "psfs_filtered = np.stack(psfs_filtered, axis=2)\n",
    "psfs = camera_obs_cond[\"psf\"]\n",
    "\n",
    "#recursivly get neighbour until mas has at least a positive neighbor.For mean above thr onli consider\n",
    "#values above thr, dont know if should be all of them and increase mask accordingly (this scale up\n",
    "#computation and iterations)\n",
    "def get_neighbors_positive_mean_at_index(image, i, j, thr, mask_size=3):\n",
    "    pad_size = mask_size//2\n",
    "    npad = ((pad_size, pad_size), (pad_size, pad_size))\n",
    "    aux_padded_image = np.pad(image, pad_width=npad, mode='constant', constant_values=0)\n",
    "    i_in_aux_image = i+pad_size\n",
    "    j_in_aux_image = j+pad_size\n",
    "    neighbors = aux_padded_image[i_in_aux_image-pad_size:i_in_aux_image+pad_size+1,j_in_aux_image-pad_size:j_in_aux_image+pad_size+1]\n",
    "    positive_mean = np.mean(neighbors[neighbors>=thr])\n",
    "    #if mask_size>3:\n",
    "    #    print('image(%i,%i): %.16f, mean: %.16f mask_size %i\\n %s , ' % (\n",
    "    #        i, j, image[i,j], positive_mean, mask_size, str(neighbors)))\n",
    "    if np.isnan(positive_mean):\n",
    "    #    print('image(%i,%i): %.16f, mean: %.16f mask_size %i\\n %s , ' % (\n",
    "    #        i, j, image[i,j], positive_mean, mask_size, str(neighbors)))\n",
    "        return get_neighbors_positive_mean_at_index(image, i, j, thr, mask_size+2)\n",
    "    else:\n",
    "        return positive_mean\n",
    "\n",
    "#replace negative values with neighbours mean\n",
    "#given a image replace values below threshold with mean of neghbours.\n",
    "def NN_threshold(image, thr):\n",
    "    image_to_return = np.copy(image)\n",
    "    x, y = image.shape\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            if image[i,j] < thr:\n",
    "                #if i>10 and i<16 and j>10 and j<16:\n",
    "                #    print('(%i,%i)'%(i,j))\n",
    "                positive_mean = get_neighbors_positive_mean_at_index(image, i, j, thr)\n",
    "                image_to_return[i,j] = positive_mean\n",
    "    return image_to_return\n",
    "\n",
    "def NN_threshold_array(data_array):\n",
    "    for i in range(data_array.shape[-1]):\n",
    "        #print('\\nPSF %i' % i)\n",
    "        data_array[...,i] = NN_threshold(data_array[...,i], thr=0)\n",
    "    return data_array\n",
    "\n",
    "psfs_filtered_and_positive = NN_threshold_array(psfs_filtered)\n",
    "print(psfs_filtered_and_positive.shape)\n",
    "print(np.mean(psfs_filtered_and_positive>=0))\n",
    "camera_obs_cond[\"psf\"] = psfs_filtered_and_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Manually filter outbad psfs\n",
    "psfs_to_plot = psfs_filtered_and_positive\n",
    "#for i in range(psfs_to_plot.shape[-1]):\n",
    "#    print(i)\n",
    "#    plt.imshow(psfs_to_plot[...,i])\n",
    "#    plt.colorbar()\n",
    "#    plt.show()\n",
    "psfs_to_plot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate camera_obs_cond[\"camera_params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_obs_cond[\"camera_params\"] = {}\n",
    "camera_obs_cond[\"camera_params\"][\"CCD01\"] = {'ccd_num': 1,\n",
    "                                             'gain': 5.0, #[e-/ADU]\n",
    "                                             'read_noise': 11.1, #[e-]\n",
    "                                             'saturation': 350000.0, #[ADU]\n",
    "                                             'pixel_scale': 1, #[arcsec/pixel]\n",
    "                                             'zp_g': 25.399156, #camera zero point not used\n",
    "                                             'zp_i': 25.313254,\n",
    "                                             'zp_r': 25.474396,\n",
    "                                             'zp_u': 23.546145}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(camera_obs_cond, open('generated_data/ztf_conditions_postive_psfs_v5.pkl', 'wb'), protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_obs_cond['psf'][...,0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#visualice filtered psfs\n",
    "psfs = camera_obs_cond[\"psf\"]\n",
    "#for i in range(psfs.shape[-1]):\n",
    "#    print('index %i, min values %f' % (i, np.min(psfs[...,i])))\n",
    "#    plt.imshow(psfs[...,i])\n",
    "#    plt.colorbar()\n",
    "#    plt.show()\n",
    "psfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
